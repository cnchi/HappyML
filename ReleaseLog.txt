[20230210-01] BUGFIX, NEW

* [BUGFIX] preprocessor.py
- 修正 feature_scaling() 函數，傳入 pandas.Series 而非 pandas.DataFrame 時，引發的錯誤訊息。原先沒有考慮到一維的 Series。目前改成一律用 pandas.DataFrame() 轉換函數，轉成 DataFrame 之後，再進行後續的處理步驟之方法解決。

* [NEW] regression.py
- 替 MultipleRegressor 增加一個屬性，叫做 .named_features。它可以用「欄位名稱」，傳回除了 "const" 以外的降維結果。如：['R&D Spend', 'Marketing Spend']。


[20230205-01] MODIFY, NEW

* [MODIFY] regression.py
- 修正引入的多元線性迴歸函式庫。
本來： import statsmodels.regression.linear_model as sm
後來： import statsmodels.api as sm

* [NEW] regression.py
- 替 class MultipleRegressor 增加「自動增加常數項」的功能。包含：
1. 新增 add_constant(self, exog)，全自動判斷是否已經加了常數項。
2. 在 backward_elimination(), fit(), predict() 一開頭，都先呼叫 add_constant()，確保有常數項。
- 新增針對 X_train, X_test 自動切片功能。
1. 若有做過 backward_elimination()，則 __features 存在，先切片再擬合、預測。
2. 若沒做過 backward_elimination()，則 __features 不存在，代表不需降維。直接擬合、預測。


[20210606-01] BUGFIX

* [BUGFIX] criteria.py
- 修正叫用 criteria.AssumptionChecker.features_correlation() 時，若 heatmap=True，用 Seaborn 畫出來的 Heapmap，會跟其它圖形重疊在一起的問題。這是因為用 sns.heatmap(data=corr, annot=True) 之後，沒有馬上使用 plt.show()，導致繪製好的熱區圖，一直停留在記憶體中。如果後續還有繪製其它圖形，就會疊加在 Seaborn 留在記憶體中的熱區圖上面。目前已經在 sns.heatmap(data=corr, annot=True) 後方，添加了一道 plt.show()，強迫 Seaborn 把繪製好的熱區圖（Heatmap），馬上從記憶體輸出到螢幕上。所以，此一現象已經不會再發生了。


[20210603-01] BUGFIX

* [BUGFIX] model_drawer.py
- 修正呼叫 sample_model()、classify_result()、cluster_drawer() 時，如果 title= 裡面的文字並未用使用中文，也就是沒有指定 font= 參數、放任它使用預設值時，會出現「findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans」這個警告訊息之問題。這是因為原先 font= 的預設值是 font="Arial Unicode MS"。如果程式師呼叫 sample_model()、classify_result()、cluster_drawer() 三函數時，沒有特意指定 font= 的值，放任它使用預設值，而使用人的電腦內，又沒有 "Arial Unicode MS" 這個字型時，就會發出「findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans」這個警告訊息。目前已經將 font= 的預設值，改成 font="" 了。


[20210526-01] BUGFIX

* [BUGFIX] preprocessor.py
- 修正呼叫 preprocessor.PCASelector.fit() 時，不論指定 verbose=True 或 verbose=False，出來的訊息都一樣之問題。除了修正一個 verbose=True 的邏輯錯誤外，也大量添加當 verbose=True 時，秀出來的訊息。這次 verbose=True 添加的訊息包括 (1) 秀出每個 PCA 元素，所涵蓋的資訊量 (2) 秀出挑選幾個 PCA 元素後，累加的資訊量會有多少。


[20210519-01] MODIFY, BUGFIX

* [MODIFY] preprocessor.py
- 將 KBestSelector.fit() 裡面的 auto=False 參數移除。移除原因為該參數已經不再具備任何作用。早在 2019 年的版本，就已經使用 KBestSelector.__init__() 裡面的 best_k="auto" 取代之了。

* [BUGFIX] preprocessor.py
- 當 KBestSelector.__init__() 內的 best_k ≠ "auto" 的情況下，就算將 KBestSelector.fit() 裡面的 verbose=True，也會看不到 KBestSelector.fit() 逐步計算過程。這個問題是出自於程式邏輯考慮不周。原版所有 verbose=True 的機制，全部都內縮於 "auto" 之下。所以只有在 best_k="auto" 時，指定 verbose=True 才會有用。目前已經將整個 KBestSelector.fit() 裡面，與 verbose 有關的邏輯全部重新改寫，不會再出現這個現象了。

* [BUGFIX] performance.py
- 呼叫 performance.GridSearch() 建構函數時，會出現 "無效的 iid= 參數" 錯誤訊息。這是因為 performance.GridSearch() 建構函數裡面會呼叫 sklearn.model_selection.GridSearchCV()。原本呼叫 GridSearchCV() 時，需要一個 iid= 參數。後來在 sklearn 新版中，已經將 GridSearchCV() 裡面的 iid= 參數拿掉了。所以才會出現 "無效的 iid= 參數" 這個錯誤訊息。目前我已經將 performance.GridSearch() 建構函數裡面，GridSearchCV() 的 iid= 參數拿掉了。


[20200803-01] NEW

* [NEW] model_drawer.py
- 新增 show_first_n_images() 函數。它可以讓你在做「卷積神經網路」時，秀出前 N 張圖形。藉以驗證圖形載入後，處於沒問題可用的狀態。

* [NEW] neural_networks.py
- 新增 create_seq_model() 函數。讓你用一個函數，就能做到神經網路序列模型中，繁複的隱藏層添加任務。


[20200726-01] NEW
* [NEW] model_drawer.py
- 為了神經網路做完之後圖形繪製的方便，新增一個 epochs_metrics_plot() 函數。它可以繪製出「訓練集 vs. 驗證集」的效能差異，藉以看出是否過擬合。


[20191012-01] MODIFY
* [MODIFY] preprocessor.py, missing_data()
- 加上一個條件判斷： if (type(dataset) is pd.DataFrame) and (sum(dataset.isnull().sum()) > 0)。用來判斷是否為 DataFrame，以及是否需要缺失資料補遺。
- 使用 missing_cols = [i for i, j in enumerate(dataset.isnull().any()) if j]，自動判斷缺失欄位。不必使用者告知缺失欄位是哪幾個。
- 因為有自動判斷缺失欄位，所以就算沒有缺失欄位，也可以呼叫。並不會造成任何「無缺失」欄位的任何改變。


[20190918-01] BUGFIX

* [BUGFIX] regression.py Line# 35
- 原本使用 import statsmodels.formula.api as sm 匯入的套件，現在要改成 import statsmodels.regression.linear_model as sm 這樣才能匯入。


[20190826-01] BUBFIX & MODIFY & NEW

* [BUGFIX] preprocessor.missing_data(ary, strategy="mean")
- 原先版本還保留使用 NDArray 的樣子。目前已經修正成使用 DataFrame 的版本了。

* [MODIFY] preprocessor.decomposition(dataset, x_columns, y_columns=[])
- 原本 y_columns 是個「必傳」的參數。因為「集群（Clustering）」問題，只有自變數，沒有應變數，因此修改成 y_columns=[]。
- 當你不提供 y_columns 時，它會使用預設值 []，導致不會回傳任何應變數（集群問題沒有任何應變數）。

* [NEW] clustering.KMeansCluster
- 新增 KMeansCluster 類別，實作 K-Means 集群演算法。

* [NEW] model_drawer.cluster_drawer(x, y, centroids, title="", font='Arial Unicode MS')
- 可以用來將集群結果視覺化的函數。
- x: DataFrame, 只能有兩個 Features。y: DataFrame, 集群預設結果。centroids: 各集群的中心點。

* [NEW] preprocessor.combine(dataset, y_pred)
- 可以將 y_pred 的答案，附加到 dataset 尾部
- 適合用於集群分析取得答案後，黏到 dataset 的尾部。


[20190817-01] BUGFIX & NEW

* [BUGFIX] model_drawer
- 該模組內有一個函數，叫做 tree_drawer（），需要 import pydotplus 後才能運作。
- 而 pydotplus 是需要 pip install pydotplus 之後，才有辦法使用的。
- 當使用者 from robert.model_drawer import <tree_drawer() 以外的函數>，且沒有安裝 pydotplus 時，系統會發出 ImportError 說：「無法引入 pydotplut」。
- 加上下列機制，讓使用者沒有安裝 pydotplus，也可以引用 robert.model_drawer 裡 tree_drawer() 以外的其它函數。
try:
    import pydotplus
except ImportError:
    pass

* [BUGFIX] preprocessor.feature_scaling(fit_ary, transform_arys=None)
- 當 transform_arys 只有一個時，使用者容易寫成 pp.feature_scaling(fit_ary=X, transform_arys=X)
- 但 transform_arys 程式內部就直接把它當成 tuple 了。所以使用者如上述方法叫用，會失敗。
- 正確叫法應該是 pp.feature_scaling(fit_ary=X, transform_arys=(X,))。別忘了單一元素的 tuple 要寫成 (X,)
- 為了讓使用者自由使用 Tuple 與單一元素。程式碼改成這樣：
if type(transform_arys) is tuple:
    return (pd.DataFrame(scaler.transform(ary.astype("float64")), index=ary.index, columns=ary.columns) for ary in transform_arys)
else:
    return pd.DataFrame(scaler.transform(transform_arys.astype("float64")), index=transform_arys.index, columns=transform_arys.columns)
- 如此一來，使用者也可以用 pp.feature_scaling(fit_ary=X, transform_arys=X) 這種方法叫用了。

* [BUGFIX] preprocessor.KBestSelector
- 當有人這麼寫的時候：
selector = KBestSelector(best_k=2)
X = selector.fit(x_ary=X, y_ary=Y, auto=True, verbose=True, sort=True).transform(x_ary=X)
- 會因為 auto=True，導致 best_k=2 失效。所以改成KBestSelector(best_k=??) best_k= "auto" | <整數> 的寫法
if type(best_k) is int:
    self.__strategy = "fixed"
    self.best_k = best_k
else:
    self.__strategy = "auto"
    self.best_k = 1
- 而 KBestSelector.fit(x_ary=X, y_ary=Y, auto=True, verbose=True, sort=True) 中的 auto=True/False 目前保留但不作用。將在下一版移除。

* [BUGFIX] performance.KFoldClassificationPerformance
- 每次 K 折運算時，只要某一折內，不含特定應變數 Y 的某種答案，就會發出以下警告訊號：
Warning: The least populated class in y has only 5 members, which is too few.
UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples
- 加上這個選項，讓 Warning 不再出現。只有 Error 才出現：
import warnings
warnings.filterwarnings('ignore')

* [NEW] preprocessor.PCASelector
- 新增 PCASelector 類別，實作以 PCA 將特性（Features）降維




[20190813-01] MODIFY & NEW

* [MODIFY] preprocessor.label_encoder(ary, mapping=False)
- 新增一個參數 mapping=False
- 當 mapping=True 時，會傳回來兩個值
	(1) LabelEncode 過的 DataFrame 陣列
	(2) 對應字典。如 {0:"Yes", 1:"No"}，就是把 Yes 編碼為 0，No 編碼為 "1"

* [MODIFY] preprocessor.onehot_encoder(ary, columns=[], remove_trap=False)
- 新增一個參數 remove_trap=False
- 當 remove_trap=True 時，會自動移除 One Hot Encoder 後的一欄，以去除自變數共線性。
- 會自動保持原來的欄位順序。不會因為執行 One Hot Encoder，而改變欄位順序。

* [NEW] classification.DecisionTree
- 新增 DecisionTree 類別，實作 Decision Tree。

* [NEW] classification.RandomForest
- 新增 RandomForest 類別，實作 Random Forest

* [NEW] model_drawer.tree_drawer()
- 新增 tree_drawer()，以繪製 Decision Tree 的分類結果。